--- Hydra Config (See generate/evaluate) ---
model:
  model_id: Qwen/Qwen3-0.6B
  lora_rank: 128
  lora_alpha: 64
  use_custom_head: false
dataset:
  num_train_examples_per_task: 3
  num_datapoints_per_task: 50
  val_ratio: 0.05
  seed: 1234
train:
  use_data_augmentation: false
  num_train_epochs: 5
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 4
  gradient_checkpointing: false
  eval_strategy: steps
  eval_steps: 10000
  logging_strategy: steps
  logging_steps: 100
  report_to: none
  save_strategy: steps
  save_steps: 500
  save_total_limit: 3
  optim: paged_adamw_8bit
  learning_rate: 5.0e-05
  max_grad_norm: 1.0
  lr_scheduler_type: linear
  warmup_ratio: 0.05
  fp16: true
  resume_from_checkpoint: null
  patience: 5
  metric_for_best_model: eval_loss
  greater_is_better: false
  dataset_num_proc: 4
evaluate:
  num_samples: 100
  visualize: false
  num_workers: 4
  eval_name: peft-model-aug-qwen4b-r16-test-aug-naive-custom-head
generate:
  checkpoint_path: ${artifacts_dir}/train-aug-baseline-qwen4b-r16-custom-head/checkpoints/checkpoint-final
  enable_ttt: true
  use_data_augmentation_for_generation: true
  num_augmentations: 10
  batch_size_generation: 2
  grid_select_policy: naive
token: null
workspace: /home/top321902/code/intro_dl/term_project
cache_dir: null
dataset_dir: ${workspace}/dataset
artifacts_dir: ${workspace}/skeleton/artifacts
evaluation_dir: ${workspace}/evaluation
artifact_name: train-augment-qwen0.6b-rank16

[38;5;4m‚Ñπ Loading data...[0m
ÌååÏùº Î°úÎî©:   0%|          | 0/300 [00:00<?, ?it/s]ÌååÏùº Î°úÎî©:   7%|7         | 22/300 [00:00<00:01, 200.29it/s]ÌååÏùº Î°úÎî©:  15%|#5        | 46/300 [00:00<00:01, 215.75it/s]ÌååÏùº Î°úÎî©:  23%|##3       | 70/300 [00:00<00:01, 203.44it/s]ÌååÏùº Î°úÎî©:  30%|###       | 91/300 [00:00<00:02, 83.85it/s] ÌååÏùº Î°úÎî©:  37%|###7      | 112/300 [00:00<00:01, 105.30it/s]ÌååÏùº Î°úÎî©:  44%|####3     | 131/300 [00:01<00:01, 120.02it/s]ÌååÏùº Î°úÎî©:  52%|#####2    | 157/300 [00:01<00:00, 149.86it/s]ÌååÏùº Î°úÎî©:  60%|#####9    | 179/300 [00:01<00:00, 165.80it/s]ÌååÏùº Î°úÎî©:  67%|######7   | 202/300 [00:01<00:00, 181.76it/s]ÌååÏùº Î°úÎî©:  75%|#######4  | 224/300 [00:02<00:01, 67.22it/s] ÌååÏùº Î°úÎî©:  81%|########1 | 244/300 [00:02<00:00, 82.43it/s]ÌååÏùº Î°úÎî©:  88%|########8 | 264/300 [00:02<00:00, 97.76it/s]ÌååÏùº Î°úÎî©:  94%|#########3| 282/300 [00:02<00:00, 84.23it/s]ÌååÏùº Î°úÎî©: 100%|##########| 300/300 [00:02<00:00, 108.97it/s]
[38;5;2m‚úî Loaded 100 samples.[0m
[38;5;4m‚Ñπ Initializing solver...[0m
Config path: /home/top321902/code/intro_dl/term_project/skeleton/artifacts/train-aug-baseline-qwen4b-r16-custom-head/config.yaml
--- Hydra Config from checkpoint (See model) ---
model:
  model_id: Qwen/Qwen3-4B
  lora_rank: 16
  lora_alpha: 64
  use_custom_head: true
dataset:
  num_train_examples_per_task: 3
  num_datapoints_per_task: 50
  val_ratio: 0.05
  seed: 1234
train:
  use_data_augmentation: true
  num_train_epochs: 5
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 4
  gradient_checkpointing: false
  eval_strategy: steps
  eval_steps: 10000
  logging_strategy: steps
  logging_steps: 100
  report_to: none
  save_strategy: steps
  save_steps: 500
  save_total_limit: 3
  optim: paged_adamw_8bit
  learning_rate: 5.0e-05
  max_grad_norm: 1.0
  lr_scheduler_type: linear
  warmup_ratio: 0.05
  fp16: true
  resume_from_checkpoint: null
  patience: 5
  metric_for_best_model: eval_loss
  greater_is_better: false
  dataset_num_proc: 4
evaluate:
  num_samples: 100
  visualize: false
  num_workers: 4
  eval_name: aug-qwen4b-r16-no-test-aug-no-ttt
predict:
  checkpoint_path: ${artifacts_dir}/train-aug-baseline-qwen4b-r16/checkpoints/checkpoint-final
  enable_ttt: true
  use_data_augmentation_for_eval: false
  num_augmentations: 10
token: null
workspace: /home/top321902/code/intro_dl/term_project
cache_dir: null
dataset_dir: ${workspace}/dataset
artifacts_dir: ${workspace}/skeleton/artifacts
evaluation_dir: ${workspace}/evaluation
artifact_name: train-aug-baseline-qwen4b-r16-custom-head

No cache dir found, using default cache location.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|###3      | 1/3 [00:01<00:03,  1.87s/it]Loading checkpoint shards:  67%|######6   | 2/3 [00:03<00:01,  1.67s/it]Loading checkpoint shards: 100%|##########| 3/3 [00:03<00:00,  1.15s/it]
‚úì Model loaded: Qwen/Qwen3-4B
Added 392 tokens from prompt templates
‚úì Model vocabulary optimized for ARC: 226 tokens kept
‚úì Model vocabulary optimization applied
Loaded LoRA adapter and tokenizer from checkpoint.
100Í∞úÏùò ÏÉòÌîåÏóê ÎåÄÌï¥ ÌèâÍ∞ÄÎ•º ÏãúÏûëÌï©ÎãàÎã§...
ÌèâÍ∞Ä ÏßÑÌñâ:   0%|          | 0/100 [00:00<?, ?it/s]Test Input:
[[7 1 8 7 5 8 9 9]
 [1 1 8 7 7 8 7 7]
 [1 1 8 7 7 8 7 7]
 [1 1 8 7 7 8 9 9]
 [1 1 8 7 7 8 7 7]
 [1 1 8 5 7 8 7 9]
 [1 1 8 7 5 8 9 9]]

Ground Truth:
[[9 1]
 [1 1]
 [1 1]
 [1 1]
 [1 1]
 [1 1]
 [1 1]]

Predictions:
[[7 5]
 [1 1]
 [1 1]
 [1 1]
 [1 1]
 [7 1]
 [1 1]]

Score: 0
ÌèâÍ∞Ä ÏßÑÌñâ:   1%|1         | 1/100 [00:13<21:51, 13.24s/it]Test Input:
[[8 8 2]
 [8 5 8]
 [2 2 8]]

Ground Truth:
[[8 8 2 2 8 8]
 [8 5 8 2 5 8]
 [2 2 8 8 8 2]
 [2 8 8 8 2 2]
 [8 5 2 8 5 8]
 [8 8 2 2 8 8]]

Predictions:
[[8 2 2 2 2 8]
 [8 5 8 8 5 8]
 [2 8 8 8 8 2]
 [2 2 8 8 2 2]
 [8 5 8 8 5 8]
 [8 8 2 2 8 8]]

Score: 0
ÌèâÍ∞Ä ÏßÑÌñâ:   2%|2         | 2/100 [00:45<40:09, 24.58s/it]Test Input:
[[1 1 1 1 1 1 1 1]
 [1 4 4 4 4 1 1 1]
 [1 4 5 8 4 1 1 1]
 [1 4 9 0 4 1 1 1]
 [1 4 4 4 4 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]]

Ground Truth:
[[0 1 1 1 1 9 1 1]
 [1 4 4 4 4 1 1 1]
 [1 4 1 1 4 1 1 1]
 [1 4 1 1 4 1 1 1]
 [1 4 4 4 4 1 1 1]
 [8 1 1 1 1 5 1 1]
 [1 1 1 1 1 1 1 1]]

Predictions:
[[0 1 1 1 1 9 1 1]
 [1 4 4 4 4 1 1 1]
 [1 4 1 1 4 1 1 1]
 [1 4 1 1 4 1 1 1]
 [1 4 4 4 4 1 1 1]
 [1 1 1 1 1 1 1 1]
 [8 1 1 1 1 5 1 1]]

Score: 0
ÌèâÍ∞Ä ÏßÑÌñâ:   3%|3         | 3/100 [01:36<59:06, 36.57s/it]Test Input:
[[7 5 3 2 7 4 7]
 [7 0 5 8 7 6 7]
 [7 7 7 7 7 4 7]
 [7 7 7 7 7 4 7]
 [7 7 7 7 7 4 7]
 [7 7 7 7 7 4 7]
 [7 7 7 7 7 6 7]
 [7 7 7 7 7 4 7]
 [7 7 7 7 7 4 7]]

Ground Truth:
[[7 5 3 2 7 4 7]
 [7 0 5 8 7 6 7]
 [7 5 3 2 7 4 7]
 [7 5 3 2 7 4 7]
 [7 5 3 2 7 4 7]
 [7 5 3 2 7 4 7]
 [7 0 5 8 7 6 7]
 [7 5 3 2 7 4 7]
 [7 5 3 2 7 4 7]]

Predictions:
[[7 5 3 2 7 4 7]
 [7 0 5 8 7 6 7]
 [7 5 3 2 7 4 7]
 [7 5 3 2 7 4 7]
 [7 5 3 2 7 4 7]
 [7 5 3 2 7 4 7]
 [7 0 5 8 7 6 7]
 [7 5 3 2 7 4 7]
 [7 5 3 2 7 4 7]]

Score: 1
ÌèâÍ∞Ä ÏßÑÌñâ:   4%|4         | 4/100 [02:34<1:12:03, 45.03s/it]Test Input:
[[2 2 2 2 2 2 2 2 2 2]
 [2 2 2 2 2 2 2 2 2 2]
 [2 2 2 2 2 2 2 2 2 2]
 [2 2 2 2 2 2 2 2 2 2]
 [2 2 3 3 3 2 2 2 2 2]
 [2 2 3 2 3 2 2 2 2 2]
 [2 2 3 2 3 2 2 3 3 3]
 [3 3 3 2 3 3 3 3 2 3]
 [2 2 3 2 3 2 2 3 3 3]
 [2 2 3 3 3 2 2 2 3 2]]

Ground Truth:
[[2 2 2 2 2 2 2 2 2 2]
 [2 2 2 2 2 2 2 2 2 2]
 [2 2 2 2 2 2 2 2 2 2]
 [2 2 2 2 2 2 2 2 2 2]
 [2 2 3 3 3 2 2 2 2 2]
 [2 2 3 4 3 2 2 2 2 2]
 [2 2 3 4 3 2 2 3 3 3]
 [3 3 3 4 3 3 3 3 4 3]
 [2 2 3 4 3 2 2 3 3 3]
 [2 2 3 3 3 2 2 2 3 2]]

Predictions:
[[2 2 2 2 2 2 2 2 2 2]
 [2 2 2 2 2 2 2 2 2 2]
 [2 2 2 2 2 2 2 2 2 2]
 [2 2 2 2 2 2 2 2 2 2]
 [2 2 3 3 3 2 2 2 2 2]
 [2 2 3 4 3 2 2 2 2 2]
 [2 2 3 4 3 2 2 3 3 3]
 [3 3 3 4 3 3 3 3 4 3]
 [2 2 3 4 3 2 2 3 3 3]
 [2 2 3 3 3 2 2 2 3 2]]

Score: 1
ÌèâÍ∞Ä ÏßÑÌñâ:   5%|5         | 5/100 [04:14<1:42:27, 64.72s/it]Test Input:
[[0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0]
 [0 0 0 5 0 0 0]
 [0 0 0 3 0 0 5]
 [0 0 0 3 0 0 3]
 [3 3 3 3 3 3 3]]

Ground Truth:
[[0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0]
 [0 0 0 3 0 0 0]
 [0 0 0 3 0 0 3]
 [3 3 3 5 3 3 5]]

Predictions:
[[0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0]
 [5 0 0 0 0 0 0]
 [3 0 0 0 0 0 0]
 [3 3 3 3 3 3 3]]

Score: 0
ÌèâÍ∞Ä ÏßÑÌñâ:   6%|6         | 6/100 [05:35<1:50:14, 70.36s/it]Test Input:
[[5 3 3 3]
 [3 3 3 3]
 [3 5 3 3]
 [3 5 5 3]
 [3 3 3 3]
 [3 3 3 3]]

Ground Truth:
[[3 0 0 0]
 [0 0 0 0]
 [0 3 0 0]
 [0 3 3 0]
 [0 0 0 0]
 [0 0 0 0]]

Predictions:
[[0 5 5 5]
 [5 5 5 5]
 [5 0 5 5]
 [5 0 0 5]
 [5 5 5 5]
 [5 5 5 5]]

Score: 0
ÌèâÍ∞Ä ÏßÑÌñâ:   7%|7         | 7/100 [05:58<1:25:12, 54.97s/it]Test Input:
[[9 8 9]
 [1 8 9]
 [3 9 9]
 [9 6 1]]

Ground Truth:
[[9 8 9 9 8 9]
 [1 8 9 9 8 1]
 [3 9 9 9 9 3]
 [9 6 1 1 6 9]
 [9 6 1 1 6 9]
 [3 9 9 9 9 3]
 [1 8 9 9 8 1]
 [9 8 9 9 8 9]]

Predictions:
[[9 8 9 9 8 9]
 [1 8 9 9 8 1]
 [3 9 9 9 9 3]
 [9 6 1 1 6 9]
 [9 6 1 1 6 9]
 [3 9 9 9 9 3]
 [1 8 9 9 8 1]
 [9 8 9 9 8 9]]

Score: 1
ÌèâÍ∞Ä ÏßÑÌñâ:   8%|8         | 8/100 [06:43<1:19:23, 51.77s/it]Test Input:
[[2 2 2 2 2 2 2 2 2 2]
 [2 2 2 2 2 2 2 2 2 2]
 [2 2 2 6 2 2 2 2 2 2]
 [2 2 2 6 2 2 2 2 2 2]]

Ground Truth:
[[2 2 2 2 2 2 2 2 2 2]
 [2 2 2 2 2 2 2 2 2 2]
 [2 2 2 6 2 2 2 2 2 2]
 [2 2 8 6 8 2 2 2 2 2]]

Predictions:
[[2 2 2 2 2 2 2 2 2 2]
 [2 2 2 2 2 2 2 2 2 2]
 [2 2 2 6 2 2 2 2 2 2]
 [2 2 8 6 8 2 2 2 2 2]]

Score: 1
ÌèâÍ∞Ä ÏßÑÌñâ:   9%|9         | 9/100 [07:23<1:12:40, 47.92s/it]Test Input:
[[3 7 5 7 7 5 7 7]
 [7 3 5 7 7 5 7 7]
 [7 7 5 3 7 5 7 3]
 [5 5 5 5 5 5 5 5]
 [7 3 5 3 7 5 7 7]
 [7 7 5 7 7 5 7 3]
 [7 7 5 7 7 5 3 7]]

Ground Truth:
[[1 7 7]
 [7 7 1]]

Predictions:
[[7 1]
 [7 1]
 [1 7]]

Score: 0
ÌèâÍ∞Ä ÏßÑÌñâ:  10%|#         | 10/100 [07:31<53:21, 35.57s/it] Test Input:
[[4 4 4 4 4 4 4 4 4 4]
 [4 4 4 4 4 4 4 4 4 4]
 [6 6 4 4 4 6 6 6 4 4]
 [6 4 4 4 4 4 4 6 4 4]
 [6 4 6 6 4 6 6 6 4 4]
 [6 4 4 4 4 4 4 6 4 4]
 [6 4 4 4 4 4 4 6 4 4]
 [6 6 6 4 6 6 6 6 4 4]
 [4 4 4 4 4 4 4 4 4 4]
 [4 4 4 4 4 4 4 4 4 4]]

Ground Truth:
[[4 4 4 4 4 4 4 4 4 4]
 [4 4 4 4 4 4 4 4 4 4]
 [6 6 2 2 2 6 6 6 4 4]
 [6 4 4 4 4 4 4 6 4 4]
 [6 2 6 6 2 6 6 6 4 4]
 [6 4 4 4 4 4 4 6 4 4]
 [6 4 4 4 4 4 4 6 4 4]
 [6 6 6 2 6 6 6 6 4 4]
 [4 4 4 4 4 4 4 4 4 4]
 [4 4 4 4 4 4 4 4 4 4]]

Predictions:
[[4 4 4 4 4 4 4 4 4 4]
 [4 4 4 4 4 4 4 4 4 4]
 [6 6 2 2 2 6 6 6 4 4]
 [6 4 4 4 4 4 4 6 4 4]
 [6 2 6 6 2 6 6 6 4 4]
 [6 4 4 4 4 4 4 6 4 4]
 [6 4 4 4 4 4 4 6 4 4]
 [6 6 6 2 6 6 6 6 4 4]
 [4 4 4 4 4 4 4 4 4 4]
 [4 4 4 4 4 4 4 4 4 4]]

Score: 1
ÌèâÍ∞Ä ÏßÑÌñâ:  11%|#1        | 11/100 [09:08<1:20:40, 54.39s/it]Test Input:
[[5 5]
 [5 5]
 [9 5]
 [5 9]
 [9 9]
 [9 9]
 [5 5]
 [5 5]]

Ground Truth:
[[5 5]
 [5 5]
 [9 2]
 [2 9]
 [9 9]
 [9 9]
 [5 5]
 [5 5]]

Predictions:
[[5 5]
 [5 5]
 [9 2]
 [2 9]
 [9 9]
 [9 9]
 [5 5]
 [5 5]]

Score: 1
ÌèâÍ∞Ä ÏßÑÌñâ:  12%|#2        | 12/100 [09:26<1:03:34, 43.34s/it]Test Input:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 3 3 0 0 3 3 0 0]
 [5 0 3 0 0 0 0 3 0 5]
 [0 0 3 3 0 0 3 3 0 0]
 [0 0 0 0 0 0 0 0 0 0]]

Ground Truth:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 3 3 0 0 3 3 0 0]
 [0 0 3 0 5 5 0 3 0 0]
 [0 0 3 3 0 0 3 3 0 0]
 [0 0 0 0 0 0 0 0 0 0]]

Predictions:
[[0 0 0 0 0 0 0 0 0 0]
 [0 0 3 3 0 0 3 3 0 0]
 [0 0 3 0 5 0 0 3 0 0]
 [0 0 3 3 0 0 3 3 0 0]
 [0 0 0 0 0 0 0 0 0 0]]

Score: 0
ÌèâÍ∞Ä ÏßÑÌñâ:  13%|#3        | 13/100 [10:16<1:05:45, 45.35s/it]Test Input:
[[1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 4 1 1 1 1 9]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]]

Ground Truth:
[[1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 4 4 9 9 1]
 [1 1 1 4 1 1 9 1]
 [1 1 4 4 1 1 9 9]
 [1 1 1 4 1 1 9 1]
 [1 1 1 4 4 9 9 1]
 [1 1 1 1 1 1 1 1]]

Predictions:
[[1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 1 1 1 1 1 1]
 [1 1 4 1 1 1 1 9]
 [1 1 4 1 1 1 1 9]
 [1 4 4 4 4 4 9 9]
 [1 1 4 1 1 1 1 9]
 [1 1 1 1 1 1 1 1]]

Score: 0
ÌèâÍ∞Ä ÏßÑÌñâ:  14%|#4        | 14/100 [11:36<1:20:03, 55.85s/it]Test Input:
[[2 4 4 4 4 4 4 4 3]
 [3 4 4 4 4 4 4 4 9]
 [9 4 4 4 4 4 4 4 0]
 [8 4 4 4 4 4 4 4 3]
 [9 4 4 4 4 4 4 4 8]
 [0 4 4 4 4 4 4 4 2]
 [8 4 4 4 4 4 4 4 0]
 [4 4 4 4 4 4 4 4 4]]

Ground Truth:
[[2 2 2 2 5 3 3 3 3]
 [3 3 3 3 5 9 9 9 9]
 [9 9 9 9 5 0 0 0 0]
 [8 8 8 8 5 3 3 3 3]
 [9 9 9 9 5 8 8 8 8]
 [0 0 0 0 5 2 2 2 2]
 [8 8 8 8 5 0 0 0 0]
 [4 4 4 4 4 4 4 4 4]]

Predictions:
[[2 2 2 2 2 4 3 3 3]
 [3 3 3 3 3 5 9 9 9]
 [9 9 9 9 9 5 0 0 0]
 [8 8 8 8 8 5 3 3 3]
 [9 9 9 9 9 5 8 8 8]
 [0 0 0 0 0 5 2 2 2]
 [8 8 8 8 8 5 0 0 0]
 [4 4 4 4 4 4 4 4 4]]

Score: 0
ÌèâÍ∞Ä ÏßÑÌñâ:  15%|#5        | 15/100 [12:47<1:25:36, 60.43s/it]Test Input:
[[5 5 5 0 5 5 5]
 [5 5 3 0 5 5 5]
 [5 5 5 0 5 5 1]
 [5 5 5 0 5 5 5]
 [0 0 0 0 0 0 0]
 [3 5 5 0 5 5 5]
 [5 5 5 0 5 5 5]
 [5 5 5 0 5 5 1]
 [5 5 5 0 5 5 5]]

Ground Truth:
[[8 8 8 0 6 6 6]
 [8 8 8 0 6 6 6]
 [8 8 8 0 6 6 6]
 [8 8 8 0 6 6 6]
 [0 0 0 0 0 0 0]
 [8 8 8 0 6 6 6]
 [8 8 8 0 6 6 6]
 [8 8 8 0 6 6 6]
 [8 8 8 0 6 6 6]]

Predictions:
[[8 8 8 0 6 6 6]
 [8 8 8 0 6 6 6]
 [8 8 8 0 6 6 6]
 [8 8 8 0 6 6 6]
 [0 0 0 0 0 0 0]
 [6 6 6 0 6 6 6]
 [6 6 6 0 6 6 6]
 [6 6 6 0 6 6 6]
 [6 6 6 0 6 6 6]]

Score: 0
ÌèâÍ∞Ä ÏßÑÌñâ:  16%|#6        | 16/100 [13:49<1:25:14, 60.88s/it]Test Input:
[[2 2 2 2 4]
 [2 2 2 2 2]
 [2 2 2 2 2]
 [2 2 2 2 2]
 [2 2 2 2 2]
 [2 2 2 2 2]
 [2 2 2 2 2]
 [2 2 2 2 4]]

Ground Truth:
[[2 2 2 4 4]
 [2 2 4 4 2]
 [2 4 4 2 2]
 [4 4 2 2 2]
 [4 4 2 2 2]
 [2 4 4 2 2]
 [2 2 4 4 2]
 [2 2 2 4 4]]

Predictions:
[[2 2 2 2 4]
 [2 2 4 2 2]
 [2 4 2 2 2]
 [4 2 2 2 2]
 [2 4 2 2 2]
 [2 2 4 2 2]
 [2 2 2 4 2]
 [2 2 2 2 4]]

Score: 0
ÌèâÍ∞Ä ÏßÑÌñâ:  17%|#7        | 17/100 [14:28<1:15:14, 54.39s/it]Test Input:
[[4 4 4 4 4]
 [4 1 1 4 4]
 [4 1 1 4 4]
 [4 4 4 4 4]
 [4 4 4 4 4]
 [4 4 4 4 4]]

Ground Truth:
[[1 4 4 4 4]
 [4 1 1 4 4]
 [4 1 1 4 4]
 [4 4 4 4 4]
 [4 4 4 4 4]
 [4 4 4 4 4]]

Predictions:
[[1 4 4 4 4]
 [4 1 1 4 4]
 [4 1 1 4 4]
 [4 4 4 4 4]
 [4 4 4 4 4]
 [4 4 4 4 4]]

Score: 1
ÌèâÍ∞Ä ÏßÑÌñâ:  18%|#8        | 18/100 [14:56<1:03:19, 46.33s/it]Test Input:
[[4 9 9 9 9 9 4]
 [9 9 9 9 9 9 9]
 [2 9 9 9 9 9 2]
 [9 9 9 9 9 9 9]
 [9 9 9 9 9 9 9]
 [4 9 9 9 9 9 4]
 [9 9 9 9 9 9 9]
 [9 9 9 9 9 9 9]]

Ground Truth:
[[4 4 4 5 4 4 4]
 [9 9 9 9 9 9 9]
 [2 2 2 5 2 2 2]
 [9 9 9 9 9 9 9]
 [9 9 9 9 9 9 9]
 [4 4 4 5 4 4 4]
 [9 9 9 9 9 9 9]
 [9 9 9 9 9 9 9]]

Predictions:
[[4 9 9 9 9 9 4]
 [4 9 9 9 9 9 4]
 [4 9 9 9 9 9 4]
 [4 9 9 9 9 9 4]
 [2 9 9 9 9 9 2]
 [4 5 5 5 5 5 4]
 [4 5 5 5 5 5 4]
 [5 9 9 9 9 9 5]]

Score: 0
ÌèâÍ∞Ä ÏßÑÌñâ:  19%|#9        | 19/100 [18:00<1:58:34, 87.84s/it]Test Input:
[[0 0 3 0 0]
 [2 0 0 3 0]
 [0 8 8 8 3]
 [3 0 0 8 2]]

Ground Truth:
[[0 0 3 0 0 0 0 3 0 0]
 [2 0 0 3 0 0 3 0 0 2]
 [0 8 8 8 3 3 8 8 8 0]
 [3 0 0 8 2 2 8 0 0 3]
 [3 0 0 8 2 2 8 0 0 3]
 [0 8 8 8 3 3 8 8 8 0]
 [2 0 0 3 0 0 3 0 0 2]
 [0 0 3 0 0 0 0 3 0 0]]

